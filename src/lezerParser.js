// This file was generated by lezer-generator. You probably shouldn't edit it.
import { LRParser } from "@lezer/lr";
export const parser = LRParser.deserialize({
  version: 14,
  states:
    "#fQYQPOOOeQPO'#C_OjQPO'#CaOoQPO'#CdOzQPO'#CkOOQO'#Cj'#CjOOQO'#Cf'#CfQYQPOOOOQO,58y,58yO!PQPO,58{O!UQQO,58|OOQO,59P,59POOQO,59V,59VOOQO-E6d-E6dO!ZQPO1G.gOOQO1G.h1G.hO!`QPO7+$RO!eQPO<<GmOOQOAN=XAN=X",
  stateData:
    "!o~O]OSPOS~OSRO`POaQO~OSWO~OSXO~OcYOeZOdWX~Od[O~Ob^O~OV_O~OS`O~ObaO~OSbO~O`aSa~",
  goto: "s`PPPaPaaPaeiPPPoeTSOVTTOVQVOR]VTUOV",
  nodeNames: "âš  LineComment File Fork Label Join Assign Digit Call Def",
  maxTerm: 21,
  skippedNodes: [0, 1],
  repeatNodeCount: 1,
  tokenData:
    ")O~RgX^!jpq!j|}#_!P!Q#d!Q![$R![!]$w!]!^$|!_!`%R!c!h$f!h!i%W!i!l$f!l!m'S!m!}$f#R#S$f#T#o$f#y#z!j$f$g!j#BY#BZ!j$IS$I_!j$I|$JO!j$JT$JU!j$KV$KW!j&FU&FV!j~!oY]~X^!jpq!j#y#z!j$f$g!j#BY#BZ!j$IS$I_!j$I|$JO!j$JT$JU!j$KV$KW!j&FU&FV!j~#dOb~~#gP!P!Q#j~#oSP~OY#jZ;'S#j;'S;=`#{<%lO#j~$OP;=`<%l#jR$YSVQSP!Q![$R!c!}$f#R#S$f#T#o$fP$kSSP!Q![$f!c!}$f#R#S$f#T#o$f~$|Oe~~%ROd~~%WOc~~%]USP!Q![$f!c!q$f!q!r%o!r!}$f#R#S$f#T#o$f~%tUSP!Q![$f!c!t$f!t!u&W!u!}$f#R#S$f#T#o$f~&]USP!Q![$f!c!m$f!m!n&o!n!}$f#R#S$f#T#o$f~&vS`~SP!Q![$f!c!}$f#R#S$f#T#o$f~'XUSP!Q![$f!c!q$f!q!r'k!r!}$f#R#S$f#T#o$f~'pUSP!Q![$f!c!k$f!k!l(S!l!}$f#R#S$f#T#o$f~(XUSP!Q![$f!c!p$f!p!q(k!q!}$f#R#S$f#T#o$f~(rSa~SP!Q![$f!c!}$f#R#S$f#T#o$f",
  tokenizers: [0, 1],
  topRules: { File: [0, 2] },
  tokenPrec: 72,
});
